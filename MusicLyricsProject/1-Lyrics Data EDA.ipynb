{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Lyrics EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Description of datasets\n",
    "### 1.1 Dataset 1: Temporal Analysis and Visualisation of Music\n",
    "\n",
    "Source: https://www.kaggle.com/saurabhshahane/music-dataset-1950-to-2019  \n",
    "\n",
    "Description of dataset (Moura et al. 2020: Temporal Analysis and Visualisation of Music): \"Using spotipy we fetched data from songs of 7 musical genres (rock, reggae, jazz, blues, hip hop, country, pop) and release date ranging from 1950 to 2019. Our dataset consisted of 82452 songs distributed of 7 musical genres and release dates ranging from 1950 to 2019. The main information retained was the artist name, track name, release date, genre and track id. The track id is a unique id for each searched track. We used the ’track id’ as input to the spotipy’s audio features tool and we kept only some of these\n",
    "features. The selected features were:  \n",
    "\n",
    "• Acousticness: Presence of acoustic instruments;  \n",
    "\n",
    "• Danceability: how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm,stability, beat strength, and overall regularity;  \n",
    "\n",
    "• Loudness: The average loudness in decibels (dB) across the entire track;  \n",
    "\n",
    "• Instrumentalness: A high value describes whether a track contains fewer vocals;  \n",
    "\n",
    "• Valence: High (low) values means that the track is more happy, euphoric (sad, angry);  \n",
    "\n",
    "• Energy: Measures intensity and activity of music. Energetic tracks will be fast, loud and noisy.  \n",
    "\n",
    "(...) Using Genius API, we queried lyrics using the artist name and song name of the same songs in which we obtained the metadata. We started cleaning the texts by identifying the language using Google’s library language-detection [Shuyo 2010] and removed all non-English texts. One of the patterns found in the retrieved lyrics was the presence of bracketed texts including the artist who sings that phrase and if the phrase is either a verse, chorus, or intro. There were also texts in parentheses which in most cases were onomatopoeia or backing vocals. These texts between parenthesis/brackets were removed. We cleaned the remaining texts consisted of removing symbols, numbers, and stop words like common English words and proper nouns. The remaining words were lemmatized to its canonical form using WordNet Lemmatizer [Fellbaum 2005] provided\n",
    "by NLTK package[Bird 2009]. The data is available at [Moura 2020]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28372, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"tcc_ceds_music.csv\",delimiter=',')\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>night/time</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_name            track_name  release_date genre  \\\n",
       "0                mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "1         frankie laine             i believe          1950   pop   \n",
       "2           johnnie ray                   cry          1950   pop   \n",
       "3           pérez prado              patricia          1950   pop   \n",
       "4  giorgos papadopoulos    apopse eida oneiro          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...   54  0.048249  0.001548   \n",
       "4  till darling till matter know till dream live ...   48  0.001350  0.001350   \n",
       "\n",
       "   world/life  night/time  ...   sadness  feelings  danceability  loudness  \\\n",
       "0    0.000598    0.000598  ...  0.380299  0.117175      0.357739  0.454119   \n",
       "1    0.443435    0.001284  ...  0.001284  0.001284      0.331745  0.647540   \n",
       "2    0.002770    0.002770  ...  0.002770  0.225422      0.456298  0.585288   \n",
       "3    0.001548    0.001548  ...  0.225889  0.001548      0.686992  0.744404   \n",
       "4    0.417772    0.001350  ...  0.068800  0.001350      0.291671  0.646489   \n",
       "\n",
       "   acousticness  instrumentalness   valence    energy       topic  age  \n",
       "0      0.997992          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1      0.954819          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2      0.840361          0.000000  0.351814  0.139112       music  1.0  \n",
       "3      0.083935          0.199393  0.775350  0.743736    romantic  1.0  \n",
       "4      0.975904          0.000246  0.597073  0.394375    romantic  1.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>night/time</th>\n",
       "      <th>shake the audience</th>\n",
       "      <th>family/gospel</th>\n",
       "      <th>romantic</th>\n",
       "      <th>communication</th>\n",
       "      <th>...</th>\n",
       "      <th>like/girls</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>2.837200e+04</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "      <td>28372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1990.236888</td>\n",
       "      <td>73.028444</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.118396</td>\n",
       "      <td>0.120973</td>\n",
       "      <td>0.057387</td>\n",
       "      <td>0.017422</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.076680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028057</td>\n",
       "      <td>0.129389</td>\n",
       "      <td>0.030996</td>\n",
       "      <td>0.533348</td>\n",
       "      <td>0.665249</td>\n",
       "      <td>3.392347e-01</td>\n",
       "      <td>0.080049</td>\n",
       "      <td>0.532864</td>\n",
       "      <td>0.569875</td>\n",
       "      <td>0.425187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.487463</td>\n",
       "      <td>41.829831</td>\n",
       "      <td>0.052370</td>\n",
       "      <td>0.178684</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.111923</td>\n",
       "      <td>0.040670</td>\n",
       "      <td>0.041966</td>\n",
       "      <td>0.106095</td>\n",
       "      <td>0.109538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058473</td>\n",
       "      <td>0.181143</td>\n",
       "      <td>0.071652</td>\n",
       "      <td>0.173218</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>3.267143e-01</td>\n",
       "      <td>0.211245</td>\n",
       "      <td>0.250972</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>0.264107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1950.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.811248e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1975.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.412975</td>\n",
       "      <td>0.595364</td>\n",
       "      <td>3.423598e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329143</td>\n",
       "      <td>0.380361</td>\n",
       "      <td>0.185714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1991.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.538612</td>\n",
       "      <td>0.679050</td>\n",
       "      <td>2.259028e-01</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.539365</td>\n",
       "      <td>0.580567</td>\n",
       "      <td>0.414286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.192608</td>\n",
       "      <td>0.197793</td>\n",
       "      <td>0.065842</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.042301</td>\n",
       "      <td>0.132136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.235113</td>\n",
       "      <td>0.032622</td>\n",
       "      <td>0.656666</td>\n",
       "      <td>0.749026</td>\n",
       "      <td>6.325298e-01</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.738252</td>\n",
       "      <td>0.772766</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>0.647706</td>\n",
       "      <td>0.981781</td>\n",
       "      <td>0.962105</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.497463</td>\n",
       "      <td>0.545303</td>\n",
       "      <td>0.940789</td>\n",
       "      <td>0.645829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594459</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>0.958810</td>\n",
       "      <td>0.993502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       release_date           len        dating      violence    world/life  \\\n",
       "count  28372.000000  28372.000000  28372.000000  28372.000000  28372.000000   \n",
       "mean    1990.236888     73.028444      0.021112      0.118396      0.120973   \n",
       "std       18.487463     41.829831      0.052370      0.178684      0.172200   \n",
       "min     1950.000000      1.000000      0.000291      0.000284      0.000291   \n",
       "25%     1975.000000     42.000000      0.000923      0.001120      0.001170   \n",
       "50%     1991.000000     63.000000      0.001462      0.002506      0.006579   \n",
       "75%     2007.000000     93.000000      0.004049      0.192608      0.197793   \n",
       "max     2019.000000    199.000000      0.647706      0.981781      0.962105   \n",
       "\n",
       "         night/time  shake the audience  family/gospel      romantic  \\\n",
       "count  28372.000000        28372.000000   28372.000000  28372.000000   \n",
       "mean       0.057387            0.017422       0.017045      0.048681   \n",
       "std        0.111923            0.040670       0.041966      0.106095   \n",
       "min        0.000289            0.000284       0.000289      0.000284   \n",
       "25%        0.001032            0.000993       0.000923      0.000975   \n",
       "50%        0.001949            0.001595       0.001504      0.001754   \n",
       "75%        0.065842            0.010002       0.004785      0.042301   \n",
       "max        0.973684            0.497463       0.545303      0.940789   \n",
       "\n",
       "       communication  ...    like/girls       sadness      feelings  \\\n",
       "count   28372.000000  ...  28372.000000  28372.000000  28372.000000   \n",
       "mean        0.076680  ...      0.028057      0.129389      0.030996   \n",
       "std         0.109538  ...      0.058473      0.181143      0.071652   \n",
       "min         0.000291  ...      0.000284      0.000284      0.000289   \n",
       "25%         0.001144  ...      0.000975      0.001144      0.000993   \n",
       "50%         0.002632  ...      0.001595      0.005263      0.001754   \n",
       "75%         0.132136  ...      0.026622      0.235113      0.032622   \n",
       "max         0.645829  ...      0.594459      0.981424      0.958810   \n",
       "\n",
       "       danceability      loudness  acousticness  instrumentalness  \\\n",
       "count  28372.000000  28372.000000  2.837200e+04      28372.000000   \n",
       "mean       0.533348      0.665249  3.392347e-01          0.080049   \n",
       "std        0.173218      0.108434  3.267143e-01          0.211245   \n",
       "min        0.005415      0.000000  2.811248e-07          0.000000   \n",
       "25%        0.412975      0.595364  3.423598e-02          0.000000   \n",
       "50%        0.538612      0.679050  2.259028e-01          0.000085   \n",
       "75%        0.656666      0.749026  6.325298e-01          0.009335   \n",
       "max        0.993502      1.000000  1.000000e+00          0.996964   \n",
       "\n",
       "            valence        energy           age  \n",
       "count  28372.000000  28372.000000  28372.000000  \n",
       "mean       0.532864      0.569875      0.425187  \n",
       "std        0.250972      0.244385      0.264107  \n",
       "min        0.000000      0.000000      0.014286  \n",
       "25%        0.329143      0.380361      0.185714  \n",
       "50%        0.539365      0.580567      0.414286  \n",
       "75%        0.738252      0.772766      0.642857  \n",
       "max        1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    hold time feel break feel untrue convince spea...\n",
       "1    believe drop rain fall grow believe darkest ni...\n",
       "2    sweetheart send letter goodbye secret feel bet...\n",
       "3    kiss lips want stroll charm mambo chacha merin...\n",
       "4    till darling till matter know till dream live ...\n",
       "5    convoy light dead ahead merchantmen trump dies...\n",
       "6    piece mindin world knowin life come bring give...\n",
       "7    care moment hold fast press lips dream heaven ...\n",
       "8    lonely night surround power read mind hour nig...\n",
       "9    tear heart seat stay awhile tear heart game st...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['lyrics'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists1=list(df1['artist_name'].unique())\n",
    "artists1.to_csv(\"artists1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique artists df1: 5426\n"
     ]
    }
   ],
   "source": [
    "print(\"No of unique artists df1: \" + str(len(artists1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE DATASET PROVIDES LYRICS IN LEMMATIZED FORM WHICH WOULD PRECLUDE SOME TYPES OF ANALYSES (RHYMES)\n",
    "#SO WE MERGE WITH A SECOND DATASET CONTAINING YEARLY BILLBOARD TOP 100 RANKING FROM 1964-2015 AND RAW LYRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset 2: 50 Years of Pop Music Lyrics\n",
    "Source: https://github.com/walkerkq/musiclyrics\n",
    "\n",
    "About dataset \"Billboard has published a Year-End Hot 100 every December since 1958. The chart measures the performance of singles in the U.S. throughout the year. Using R, I’ve combined the lyrics from 50 years of Billboard Year-End Hot 100 (1965-2015) into one dataset for analysis. You can download that dataset here.\n",
    "\n",
    "The songs used for analysis were scraped from Wikipedia’s entry for each Billboard Year-End Hot 100 Songs (e.g., 2014). This is the year-end chart, not weekly rankings. Many artists have made the weekly chart but not the final year end chart. The final chart is calculated using an inverse point system based on the weekly Billboard charts (100 points for a week at number one, 1 point for a week at number 100, etc).\n",
    "\n",
    "I used the xml and RCurl packages to scrape song and artist names from each Wikipedia entry. I then used that list to scrape lyrics from sites that had predictable URL strings (for example, metrolyrics.com uses metrolyrics.com/SONG-NAME-lyrics-ARTIST-NAME.html). If the first site scrape failed, I moved onto the second, and so on. About 78.9% of the lyrics were scraped from metrolyics.com, 15.7% from songlyrics.com, 1.8% from lyricsmode.com. About 3.6% (187/5100) were unavailable.\n",
    "\n",
    "The dataset features 5100 observations with the features rank (1-100), song, artist, year, lyrics, and source. The artist feature is fairly standardized thanks to Wikipedia, but there is still quite a bit of noise when it comes to artist collaborations (Justin Timberlake featuring Timbaland, for example). If there were any errors in the lyrics that were scraped, such as spelling errors or derivatives like \"nite\" instead of \"night,\" they haven't been corrected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Song', 'Artist', 'Year', 'Lyrics', 'Source'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"billboard_lyrics_1964-2015.csv\",delimiter=',', encoding='latin-1')\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5100.0000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>4913.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.5000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>1.400977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.8689</td>\n",
       "      <td>14.721045</td>\n",
       "      <td>0.890375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.7500</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.5000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.2500</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rank         Year       Source\n",
       "count  5100.0000  5100.000000  4913.000000\n",
       "mean     50.5000  1990.000000     1.400977\n",
       "std      28.8689    14.721045     0.890375\n",
       "min       1.0000  1965.000000     1.000000\n",
       "25%      25.7500  1977.000000     1.000000\n",
       "50%      50.5000  1990.000000     1.000000\n",
       "75%      75.2500  2003.000000     1.000000\n",
       "max     100.0000  2015.000000     5.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>wooly bully</td>\n",
       "      <td>sam the sham and the pharaohs</td>\n",
       "      <td>1965</td>\n",
       "      <td>sam the sham miscellaneous wooly bully wooly b...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>i cant help myself sugar pie honey bunch</td>\n",
       "      <td>four tops</td>\n",
       "      <td>1965</td>\n",
       "      <td>sugar pie honey bunch you know that i love yo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>i cant get no satisfaction</td>\n",
       "      <td>the rolling stones</td>\n",
       "      <td>1965</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>you were on my mind</td>\n",
       "      <td>we five</td>\n",
       "      <td>1965</td>\n",
       "      <td>when i woke up this morning you were on my mi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>youve lost that lovin feelin</td>\n",
       "      <td>the righteous brothers</td>\n",
       "      <td>1965</td>\n",
       "      <td>you never close your eyes anymore when i kiss...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>downtown</td>\n",
       "      <td>petula clark</td>\n",
       "      <td>1965</td>\n",
       "      <td>when youre alone and life is making you lonel...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>help</td>\n",
       "      <td>the beatles</td>\n",
       "      <td>1965</td>\n",
       "      <td>help i need somebody help not just anybody hel...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>cant you hear my heart beat</td>\n",
       "      <td>hermans hermits</td>\n",
       "      <td>1965</td>\n",
       "      <td>carterlewis every time i see you lookin my way...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>crying in the chapel</td>\n",
       "      <td>elvis presley</td>\n",
       "      <td>1965</td>\n",
       "      <td>you saw me crying in the chapel the tears i s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>my girl</td>\n",
       "      <td>the temptations</td>\n",
       "      <td>1965</td>\n",
       "      <td>ive got sunshine on a cloudy day when its cold...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                      Song  \\\n",
       "0     1                               wooly bully   \n",
       "1     2  i cant help myself sugar pie honey bunch   \n",
       "2     3                i cant get no satisfaction   \n",
       "3     4                       you were on my mind   \n",
       "4     5              youve lost that lovin feelin   \n",
       "5     6                                  downtown   \n",
       "6     7                                      help   \n",
       "7     8               cant you hear my heart beat   \n",
       "8     9                      crying in the chapel   \n",
       "9    10                                   my girl   \n",
       "\n",
       "                          Artist  Year  \\\n",
       "0  sam the sham and the pharaohs  1965   \n",
       "1                      four tops  1965   \n",
       "2             the rolling stones  1965   \n",
       "3                        we five  1965   \n",
       "4         the righteous brothers  1965   \n",
       "5                   petula clark  1965   \n",
       "6                    the beatles  1965   \n",
       "7                hermans hermits  1965   \n",
       "8                  elvis presley  1965   \n",
       "9                the temptations  1965   \n",
       "\n",
       "                                              Lyrics  Source  \n",
       "0  sam the sham miscellaneous wooly bully wooly b...     3.0  \n",
       "1   sugar pie honey bunch you know that i love yo...     1.0  \n",
       "2                                                        1.0  \n",
       "3   when i woke up this morning you were on my mi...     1.0  \n",
       "4   you never close your eyes anymore when i kiss...     1.0  \n",
       "5   when youre alone and life is making you lonel...     1.0  \n",
       "6  help i need somebody help not just anybody hel...     3.0  \n",
       "7  carterlewis every time i see you lookin my way...     5.0  \n",
       "8   you saw me crying in the chapel the tears i s...     1.0  \n",
       "9  ive got sunshine on a cloudy day when its cold...     3.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists2=list(df2['Artist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique artists df2: 2473\n"
     ]
    }
   ],
   "source": [
    "print(\"No of unique artists df2: \" + str(len(artists2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save unique artists to extract lyrics with genius API\n",
    "artists2=pd.DataFrame(artists2)\n",
    "artists2\n",
    "artists2.to_csv(\"artists2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Exact matching based on artist and sond title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the raw lyrics and billboard chart ranking together with the music features from the first dataset, we can merge the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join - keep only those songs present in both datasets\n",
    "#drop lyrics in df1\n",
    "df1.columns\n",
    "df1.drop(columns=['lyrics'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(df1,df2[['Artist', 'Song', 'Lyrics','Rank']],right_on=['Artist', 'Song'],left_on=['artist_name', 'track_name'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 33)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this returns few matches. we have to use fuzzy string matching, e.g. with FuzzyWuzzy package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Fuzzy String Matching with Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing FuzzyWuzzy\n",
    "#!pip install fuzzywuzzy\n",
    "#!pip install python-Levenshtein-wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import ftfy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter df1 so it contains only songs from 1964-2015\n",
    "df1_filtered=df1.loc[df1['release_date'] >= 1964 ]\n",
    "df1_fildered=  df1_filtered.loc[df1_filtered['release_date'] <= 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25681 4899\n"
     ]
    }
   ],
   "source": [
    "#combine artist and song names to single sets of strings\n",
    "artist_songs1=list((df1_filtered['artist_name']+\" \" +df1_filtered['track_name']).unique())\n",
    "artist_songs2=list((df2['Artist']+\" \" +df2['Song']).unique())\n",
    "print(len(artist_songs1),len(artist_songs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate condensed distance matrix by wrapping the Levenshtein distance function\n",
    "\n",
    "from Levenshtein import distance\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "#initializing the distance matrix\n",
    "strings1 = artist_songs2\n",
    "strings2=artist_songs1\n",
    "distances = np.zeros((len(strings1) , len(strings2) ))\n",
    "for x in range(len(strings1)):\n",
    "    l = [([strings1[x]]+[i]) for i in strings2]\n",
    "    for y in range(len(strings2)):\n",
    "        distances[x,y] = distance(l[y][0], l[y][1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape\n",
    "dist=pd.DataFrame(distances).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 50 lowest distances per row\n",
    "min=[]\n",
    "lowest=[]\n",
    "\n",
    "for r in dist:\n",
    "    #10 lowest\n",
    "    d=list((dist[r]).nsmallest(50).index)\n",
    "    low=int(dist[r].nsmallest(1))\n",
    "\n",
    "    #get min dist\n",
    "    lowest.append(low)\n",
    "    \n",
    "    #match with lists of strings\n",
    "    strings2_select = list([strings2[index] for index in d])\n",
    "    min.append(strings2_select)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=pd.DataFrame(min)\n",
    "df_m.insert(loc=0, column='strings1', value=strings1)\n",
    "df_m.insert(loc=1, column='min_dist', value=lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.sort_values(by='min_dist', inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strings1</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>pretty ricky on the hotline</td>\n",
       "      <td>0</td>\n",
       "      <td>pretty ricky on the hotline</td>\n",
       "      <td>cheap trick on the radio</td>\n",
       "      <td>sweet gold on the ceiling</td>\n",
       "      <td>greyboy on the strip</td>\n",
       "      <td>cheap trick oh caroline</td>\n",
       "      <td>ratt scene of the crime</td>\n",
       "      <td>ratt slip of the lip</td>\n",
       "      <td>ice-t 6 'n the mornin'</td>\n",
       "      <td>free lying in the sunshine</td>\n",
       "      <td>sweet fox on the run</td>\n",
       "      <td>cheap trick way of the world</td>\n",
       "      <td>oingo boingo on the outside</td>\n",
       "      <td>patty smyth the warrior</td>\n",
       "      <td>roy orbison the only one</td>\n",
       "      <td>janet jackson this time</td>\n",
       "      <td>green day all the time</td>\n",
       "      <td>celtic woman the voice</td>\n",
       "      <td>set it off the haunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>sarah mclachlan angel</td>\n",
       "      <td>0</td>\n",
       "      <td>sarah mclachlan angel</td>\n",
       "      <td>sarah mclachlan vox</td>\n",
       "      <td>sarah mclachlan fear</td>\n",
       "      <td>sarah mclachlan elsewhere</td>\n",
       "      <td>sarah mclachlan ice cream</td>\n",
       "      <td>sarah mclachlan possession</td>\n",
       "      <td>sarah mclachlan i love you</td>\n",
       "      <td>sarah mclachlan good enough</td>\n",
       "      <td>aretha franklin angel</td>\n",
       "      <td>casey donahew angel</td>\n",
       "      <td>nazareth fallen angel</td>\n",
       "      <td>basia not an angel</td>\n",
       "      <td>aaron watson san angelo</td>\n",
       "      <td>jamey johnson angel</td>\n",
       "      <td>john mclaughlin aspan</td>\n",
       "      <td>aerosmith angel</td>\n",
       "      <td>blahzay blahzay danger</td>\n",
       "      <td>joni mitchell tin angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>chicago call on me</td>\n",
       "      <td>0</td>\n",
       "      <td>chicago call on me</td>\n",
       "      <td>r.e.m. fall on me</td>\n",
       "      <td>gyptian all on me</td>\n",
       "      <td>chicago i'm a man</td>\n",
       "      <td>chicago make me smile</td>\n",
       "      <td>chicago happy man</td>\n",
       "      <td>chicago old days</td>\n",
       "      <td>a-ha take on me</td>\n",
       "      <td>fuel falls on me</td>\n",
       "      <td>chicago just you 'n' me</td>\n",
       "      <td>chicago look away</td>\n",
       "      <td>blondie call me</td>\n",
       "      <td>chicago beginnings</td>\n",
       "      <td>weezer take on me</td>\n",
       "      <td>irene cara fame</td>\n",
       "      <td>live i alone</td>\n",
       "      <td>default count on me</td>\n",
       "      <td>ashanti body on me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>the neighbourhood sweater weather</td>\n",
       "      <td>0</td>\n",
       "      <td>the neighbourhood sweater weather</td>\n",
       "      <td>the neighbourhood a little death</td>\n",
       "      <td>the neighbourhood sadderdaze</td>\n",
       "      <td>the neighbourhood female robbery</td>\n",
       "      <td>the neighbourhood wires</td>\n",
       "      <td>the neighbourhood afraid</td>\n",
       "      <td>the neighbourhood leaving tonight</td>\n",
       "      <td>the neighbourhood staying up</td>\n",
       "      <td>the neighbourhood honest</td>\n",
       "      <td>the neighbourhood prey</td>\n",
       "      <td>the neighbourhood you get me so high</td>\n",
       "      <td>the neighbourhood middle of somewhere</td>\n",
       "      <td>the neighbourhood void</td>\n",
       "      <td>the neighbourhood r.i.p. 2 my youth</td>\n",
       "      <td>the beach boys hold on, dear brother</td>\n",
       "      <td>the tennors weather report</td>\n",
       "      <td>the box tops the letter</td>\n",
       "      <td>the beach boys the trader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>nicki minaj starships</td>\n",
       "      <td>0</td>\n",
       "      <td>nicki minaj starships</td>\n",
       "      <td>nicki minaj save me</td>\n",
       "      <td>nicki minaj chun-li</td>\n",
       "      <td>nicki minaj high school</td>\n",
       "      <td>nicki minaj megatron</td>\n",
       "      <td>nicki minaj roman holiday</td>\n",
       "      <td>nicki minaj right thru me</td>\n",
       "      <td>nicki minaj did it on’em</td>\n",
       "      <td>nicki minaj pills n potions</td>\n",
       "      <td>drake scholarships</td>\n",
       "      <td>jamiroquai starchild</td>\n",
       "      <td>mike pinto darlin'</td>\n",
       "      <td>nirvana stain</td>\n",
       "      <td>nick wiz smackdown</td>\n",
       "      <td>nancy sinatra lies</td>\n",
       "      <td>adam ant strip</td>\n",
       "      <td>inxs the stairs</td>\n",
       "      <td>magic man paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>mariah carey hero</td>\n",
       "      <td>4</td>\n",
       "      <td>mariah carey the roof</td>\n",
       "      <td>mariah carey someday</td>\n",
       "      <td>mariah carey my all</td>\n",
       "      <td>mariah carey emotions</td>\n",
       "      <td>mariah carey long ago</td>\n",
       "      <td>mariah carey fantasy</td>\n",
       "      <td>mariah carey babydoll</td>\n",
       "      <td>mariah carey melt away</td>\n",
       "      <td>mariah carey without you</td>\n",
       "      <td>majid jordan her</td>\n",
       "      <td>alessia cara here</td>\n",
       "      <td>phish harry hood</td>\n",
       "      <td>marine girls honey</td>\n",
       "      <td>phish character zero</td>\n",
       "      <td>paramore my heart</td>\n",
       "      <td>train marry me</td>\n",
       "      <td>a$ap rocky peso</td>\n",
       "      <td>marina teen idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>glass tiger dont forget me when im gone</td>\n",
       "      <td>4</td>\n",
       "      <td>glass tiger don't forget me (when i'm gone)</td>\n",
       "      <td>al green don't hurt me no more</td>\n",
       "      <td>bee gees don't forget to remember</td>\n",
       "      <td>the tubes don't touch me there</td>\n",
       "      <td>dolly parton when i'm gone</td>\n",
       "      <td>marty robbins when i'm gone</td>\n",
       "      <td>america don't let me be lonely</td>\n",
       "      <td>steely dan fire in the hole</td>\n",
       "      <td>grant green down here on the ground</td>\n",
       "      <td>peter white when i'm alone</td>\n",
       "      <td>six60 don't forget your roots</td>\n",
       "      <td>swiss she don't want me love</td>\n",
       "      <td>rod stewart sometimes when we touch</td>\n",
       "      <td>nate dogg hardest man in town</td>\n",
       "      <td>barbara lewis don't forget about me</td>\n",
       "      <td>gene pitney it hurts to be in love</td>\n",
       "      <td>sparks tryouts for the human race</td>\n",
       "      <td>paul simon song about the moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>rich homie quan flex ooh ooh ooh</td>\n",
       "      <td>4</td>\n",
       "      <td>rich homie quan flex (ooh, ooh, ooh)</td>\n",
       "      <td>rich homie quan gamble</td>\n",
       "      <td>jamiroquai feel so good</td>\n",
       "      <td>richard thompson i feel so good</td>\n",
       "      <td>rita ora let you love me</td>\n",
       "      <td>ray price an eye for an eye</td>\n",
       "      <td>richie spice open the door</td>\n",
       "      <td>the beatles for no one</td>\n",
       "      <td>bring me the horizon oh no</td>\n",
       "      <td>eric carmen change of heart</td>\n",
       "      <td>chaka khan we got each other</td>\n",
       "      <td>throwing muses not too soon</td>\n",
       "      <td>lighthouse family high</td>\n",
       "      <td>michael bublé hold on</td>\n",
       "      <td>nicki minaj high school</td>\n",
       "      <td>hozier take me to church</td>\n",
       "      <td>vic mensa liquor locker</td>\n",
       "      <td>carrie underwood change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>ashanti rain on me</td>\n",
       "      <td>4</td>\n",
       "      <td>ashanti body on me</td>\n",
       "      <td>a-ha take on me</td>\n",
       "      <td>ashanti only u</td>\n",
       "      <td>ashanti happy</td>\n",
       "      <td>ashanti unfoolish</td>\n",
       "      <td>ashanti foolish</td>\n",
       "      <td>slave wait for me</td>\n",
       "      <td>r.e.m. fall on me</td>\n",
       "      <td>pj harvey rid of me</td>\n",
       "      <td>default count on me</td>\n",
       "      <td>shania twain forget me</td>\n",
       "      <td>gyptian all on me</td>\n",
       "      <td>shenseea pon mi</td>\n",
       "      <td>chicago call on me</td>\n",
       "      <td>anthrax only</td>\n",
       "      <td>staind me</td>\n",
       "      <td>weezer take on me</td>\n",
       "      <td>train free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>sweet inspirations sweet inspiration</td>\n",
       "      <td>4</td>\n",
       "      <td>the sweet inspirations sweet inspiration</td>\n",
       "      <td>the derek trucks band sweet inspiration</td>\n",
       "      <td>the melodians sweet sensation</td>\n",
       "      <td>the temper trap sweet disposition</td>\n",
       "      <td>sdib best inspiration</td>\n",
       "      <td>the sweet inspirations i'm blue</td>\n",
       "      <td>dolly parton sweet music man</td>\n",
       "      <td>israel vibration feelin' irie</td>\n",
       "      <td>groundation weeping pirates</td>\n",
       "      <td>generationals put a light on</td>\n",
       "      <td>chet atkins sweet dreams</td>\n",
       "      <td>the impressions keep on pushing</td>\n",
       "      <td>creation rebel liberation</td>\n",
       "      <td>iration meditation</td>\n",
       "      <td>scorpions alien nation</td>\n",
       "      <td>ween transdermal celebration</td>\n",
       "      <td>the kooks sweet emotion</td>\n",
       "      <td>the impressions see the real me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     strings1  min_dist  \\\n",
       "4163              pretty ricky on the hotline         0   \n",
       "3355                    sarah mclachlan angel         0   \n",
       "997                        chicago call on me         0   \n",
       "4781        the neighbourhood sweater weather         0   \n",
       "4542                    nicki minaj starships         0   \n",
       "...                                       ...       ...   \n",
       "2891                        mariah carey hero         4   \n",
       "2129  glass tiger dont forget me when im gone         4   \n",
       "4852         rich homie quan flex ooh ooh ooh         4   \n",
       "3796                       ashanti rain on me         4   \n",
       "383      sweet inspirations sweet inspiration         4   \n",
       "\n",
       "                                                0  \\\n",
       "4163                  pretty ricky on the hotline   \n",
       "3355                        sarah mclachlan angel   \n",
       "997                            chicago call on me   \n",
       "4781            the neighbourhood sweater weather   \n",
       "4542                        nicki minaj starships   \n",
       "...                                           ...   \n",
       "2891                        mariah carey the roof   \n",
       "2129  glass tiger don't forget me (when i'm gone)   \n",
       "4852         rich homie quan flex (ooh, ooh, ooh)   \n",
       "3796                           ashanti body on me   \n",
       "383      the sweet inspirations sweet inspiration   \n",
       "\n",
       "                                            1  \\\n",
       "4163                 cheap trick on the radio   \n",
       "3355                      sarah mclachlan vox   \n",
       "997                         r.e.m. fall on me   \n",
       "4781         the neighbourhood a little death   \n",
       "4542                      nicki minaj save me   \n",
       "...                                       ...   \n",
       "2891                     mariah carey someday   \n",
       "2129           al green don't hurt me no more   \n",
       "4852                   rich homie quan gamble   \n",
       "3796                          a-ha take on me   \n",
       "383   the derek trucks band sweet inspiration   \n",
       "\n",
       "                                      2                                  3  \\\n",
       "4163          sweet gold on the ceiling               greyboy on the strip   \n",
       "3355               sarah mclachlan fear          sarah mclachlan elsewhere   \n",
       "997                   gyptian all on me                  chicago i'm a man   \n",
       "4781       the neighbourhood sadderdaze   the neighbourhood female robbery   \n",
       "4542                nicki minaj chun-li            nicki minaj high school   \n",
       "...                                 ...                                ...   \n",
       "2891                mariah carey my all              mariah carey emotions   \n",
       "2129  bee gees don't forget to remember     the tubes don't touch me there   \n",
       "4852            jamiroquai feel so good    richard thompson i feel so good   \n",
       "3796                     ashanti only u                      ashanti happy   \n",
       "383       the melodians sweet sensation  the temper trap sweet disposition   \n",
       "\n",
       "                               4                                5  \\\n",
       "4163     cheap trick oh caroline          ratt scene of the crime   \n",
       "3355   sarah mclachlan ice cream       sarah mclachlan possession   \n",
       "997        chicago make me smile                chicago happy man   \n",
       "4781     the neighbourhood wires         the neighbourhood afraid   \n",
       "4542        nicki minaj megatron        nicki minaj roman holiday   \n",
       "...                          ...                              ...   \n",
       "2891       mariah carey long ago             mariah carey fantasy   \n",
       "2129  dolly parton when i'm gone      marty robbins when i'm gone   \n",
       "4852    rita ora let you love me      ray price an eye for an eye   \n",
       "3796           ashanti unfoolish                  ashanti foolish   \n",
       "383        sdib best inspiration  the sweet inspirations i'm blue   \n",
       "\n",
       "                                      6                              7  \\\n",
       "4163               ratt slip of the lip         ice-t 6 'n the mornin'   \n",
       "3355         sarah mclachlan i love you    sarah mclachlan good enough   \n",
       "997                    chicago old days                a-ha take on me   \n",
       "4781  the neighbourhood leaving tonight   the neighbourhood staying up   \n",
       "4542          nicki minaj right thru me       nicki minaj did it on’em   \n",
       "...                                 ...                            ...   \n",
       "2891              mariah carey babydoll         mariah carey melt away   \n",
       "2129     america don't let me be lonely    steely dan fire in the hole   \n",
       "4852         richie spice open the door         the beatles for no one   \n",
       "3796                  slave wait for me              r.e.m. fall on me   \n",
       "383        dolly parton sweet music man  israel vibration feelin' irie   \n",
       "\n",
       "                                        8                             9  \\\n",
       "4163           free lying in the sunshine          sweet fox on the run   \n",
       "3355                aretha franklin angel           casey donahew angel   \n",
       "997                      fuel falls on me       chicago just you 'n' me   \n",
       "4781             the neighbourhood honest        the neighbourhood prey   \n",
       "4542          nicki minaj pills n potions            drake scholarships   \n",
       "...                                   ...                           ...   \n",
       "2891             mariah carey without you              majid jordan her   \n",
       "2129  grant green down here on the ground    peter white when i'm alone   \n",
       "4852           bring me the horizon oh no   eric carmen change of heart   \n",
       "3796                  pj harvey rid of me           default count on me   \n",
       "383           groundation weeping pirates  generationals put a light on   \n",
       "\n",
       "                                        10  \\\n",
       "4163          cheap trick way of the world   \n",
       "3355                 nazareth fallen angel   \n",
       "997                      chicago look away   \n",
       "4781  the neighbourhood you get me so high   \n",
       "4542                  jamiroquai starchild   \n",
       "...                                    ...   \n",
       "2891                     alessia cara here   \n",
       "2129         six60 don't forget your roots   \n",
       "4852          chaka khan we got each other   \n",
       "3796                shania twain forget me   \n",
       "383               chet atkins sweet dreams   \n",
       "\n",
       "                                         11  \\\n",
       "4163            oingo boingo on the outside   \n",
       "3355                     basia not an angel   \n",
       "997                         blondie call me   \n",
       "4781  the neighbourhood middle of somewhere   \n",
       "4542                     mike pinto darlin'   \n",
       "...                                     ...   \n",
       "2891                       phish harry hood   \n",
       "2129           swiss she don't want me love   \n",
       "4852            throwing muses not too soon   \n",
       "3796                      gyptian all on me   \n",
       "383         the impressions keep on pushing   \n",
       "\n",
       "                                       12  \\\n",
       "4163              patty smyth the warrior   \n",
       "3355              aaron watson san angelo   \n",
       "997                    chicago beginnings   \n",
       "4781               the neighbourhood void   \n",
       "4542                        nirvana stain   \n",
       "...                                   ...   \n",
       "2891                   marine girls honey   \n",
       "2129  rod stewart sometimes when we touch   \n",
       "4852               lighthouse family high   \n",
       "3796                      shenseea pon mi   \n",
       "383             creation rebel liberation   \n",
       "\n",
       "                                       13  \\\n",
       "4163             roy orbison the only one   \n",
       "3355                  jamey johnson angel   \n",
       "997                     weezer take on me   \n",
       "4781  the neighbourhood r.i.p. 2 my youth   \n",
       "4542                   nick wiz smackdown   \n",
       "...                                   ...   \n",
       "2891                 phish character zero   \n",
       "2129        nate dogg hardest man in town   \n",
       "4852                michael bublé hold on   \n",
       "3796                   chicago call on me   \n",
       "383                    iration meditation   \n",
       "\n",
       "                                        14  \\\n",
       "4163               janet jackson this time   \n",
       "3355                 john mclaughlin aspan   \n",
       "997                        irene cara fame   \n",
       "4781  the beach boys hold on, dear brother   \n",
       "4542                    nancy sinatra lies   \n",
       "...                                    ...   \n",
       "2891                     paramore my heart   \n",
       "2129   barbara lewis don't forget about me   \n",
       "4852               nicki minaj high school   \n",
       "3796                          anthrax only   \n",
       "383                 scorpions alien nation   \n",
       "\n",
       "                                      15                                 16  \\\n",
       "4163              green day all the time             celtic woman the voice   \n",
       "3355                     aerosmith angel             blahzay blahzay danger   \n",
       "997                         live i alone                default count on me   \n",
       "4781          the tennors weather report            the box tops the letter   \n",
       "4542                      adam ant strip                    inxs the stairs   \n",
       "...                                  ...                                ...   \n",
       "2891                      train marry me                    a$ap rocky peso   \n",
       "2129  gene pitney it hurts to be in love  sparks tryouts for the human race   \n",
       "4852            hozier take me to church            vic mensa liquor locker   \n",
       "3796                           staind me                  weezer take on me   \n",
       "383         ween transdermal celebration            the kooks sweet emotion   \n",
       "\n",
       "                                   17  \n",
       "4163          set it off the haunting  \n",
       "3355          joni mitchell tin angel  \n",
       "997                ashanti body on me  \n",
       "4781        the beach boys the trader  \n",
       "4542                  magic man paris  \n",
       "...                               ...  \n",
       "2891                 marina teen idle  \n",
       "2129   paul simon song about the moon  \n",
       "4852          carrie underwood change  \n",
       "3796                       train free  \n",
       "383   the impressions see the real me  \n",
       "\n",
       "[900 rows x 20 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m2=df_m.iloc[:,0:20]\n",
    "df_m2.loc[df_m['min_dist']<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old approach\n",
    "\n",
    "# def fuzzy_merge(df1, df2, key1, key2, threshold=90, limit=1):\n",
    "#     \"\"\"\n",
    "#     :param df1: the left table to join\n",
    "#     :param df2: the right table to join\n",
    "#     :param key1_1, key1_2: key columns of the left table\n",
    "#     :param key2_1, key2_2: key columns of the right table\n",
    "#     :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "#     :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "#     :return: dataframe with boths keys and matches\n",
    "#     \"\"\"\n",
    "#     s = df2[key2].tolist()\n",
    "    \n",
    "#     m = df1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "#     df1['matches'] = m\n",
    "    \n",
    "#     m2 = df_1['matches'].apply(lambda x: ', '.merge([i[0] for i in x if i[1] >= threshold]))\n",
    "#     df1['matches'] = m2\n",
    "    \n",
    "#     return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster approach using fg-idf  \n",
    "\n",
    "https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536  \n",
    "\n",
    "Create a function to split our stings into character ngrams.  \n",
    "\n",
    "Create a tf-idf matrix from these characters using Scikit-Learn.  \n",
    "\n",
    "Use cosine similarity to show close matches across the population.  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to turn a string into a series of ngrams for matching on\n",
    "\n",
    "def ngrams(string, n=3):\n",
    "    string = ftfy.fix_text(string) # fix text encoding issues\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove all non ascii chars\n",
    "    string = string.lower() #make lower case\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string) # remove the list of chars above\n",
    "    string = string.replace('&','and')\n",
    "    string = string.replace(',',' ')\n",
    "    string = string.replace('-',' ')\n",
    "    #string = string.title() # normalize case capital at start of each word - not necessary for these data\n",
    "    string = ' '+ string + ' ' #pad names for ngrams\n",
    "    string = re.sub(r'[,,./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faster approach applying ngrams and tf-idf\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "artist_name_clean = df2['Artist'].unique()\n",
    "print(artist_name_clean)\n",
    "print('Vecorizing the data - this could take a few minutes for large datasets...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=True)\n",
    "tfidf = vectorizer.fit_transform(artist_name_clean)\n",
    "print('Vecorizing completed...')\n",
    "len(artist_name_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "\n",
    "artist_column = 'artist_name' #column to match against in the messy data\n",
    "df1_short = df1.loc[(df1['release_date']<=2015) & (df1['release_date']>=1965)] # filter df1 (1950-2019) so it contains the same years as the shorter df2 (1965-2015)\n",
    "unique_artists = set(df1_short[artist_column].values) # set used for increased performance\n",
    "len(unique_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###matching query:\n",
    "def getNearestN(query):\n",
    "  queryTFIDF_ = vectorizer.transform(query)\n",
    "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "  return distances, indices\n",
    "import time\n",
    "t1 = time.time()\n",
    "print('getting nearest n...')\n",
    "distances, indices = getNearestN(unique_artists)\n",
    "t = time.time()-t1\n",
    "print(\"COMPLETED IN:\", t)\n",
    "unique_artists = list(unique_artists) #need to convert back to a list\n",
    "print('finding matches...')\n",
    "matches = []\n",
    "for i,j in enumerate(indices):\n",
    "  temp = [round(distances[i][0],2),artist_name_clean[j][0],unique_artists[i]]\n",
    "  matches.append(temp)\n",
    "print('Building data frame...')  \n",
    "matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Original name'])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=matches.sort_values(by='Match confidence (lower is better)', axis=0, ascending=True)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.loc[matches['Match confidence (lower is better)']<0.7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other try using FuzzyWuzzy  \n",
    "Takes very long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting the artist name column of both dataframes into lists\n",
    "df1_names = list(df1.artist_name.unique())\n",
    "df2_names = list(df2.Artist.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to return the match and similarity score of the fuzz.ratio() scorer. \n",
    "#The function will take in a term(name), list of terms(list_names), \n",
    "#and a minimum similarity score(min_score) to return the match. \n",
    "def match_names(name, list_names, min_score=0):\n",
    "    max_score = -1\n",
    "    max_name = ''\n",
    "    for x in list_names:\n",
    "        score = fuzz.ratio(name, x)\n",
    "        if (score > min_score) & (score > max_score):\n",
    "            max_name = x\n",
    "            max_score = score\n",
    "    return (max_name, max_score)\n",
    "#For loop to create a list of tuples with the first value being the name from the second dataframe (name to replace) and the second value from the first dataframe (string replacing the name value). Then, casting the list of tuples as a dictionary. \n",
    "names = []\n",
    "for x in df1.artist_name:\n",
    "    match = match_names(x, df2.Artist, 75)\n",
    "    if match[1] >= 75:\n",
    "        name = ('(' + str(x), str(match[0]) + ')')\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "#df_2.name = df_2.name.replace(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = dict(names)\n",
    "\n",
    "name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
